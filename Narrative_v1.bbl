\begin{thebibliography}{10}

\bibitem{Albrecht__explioting_causality}
S~V Albrecht and S~Ramamoorthy.
\newblock {Exploiting causality for selective belief filtering in dynamic
  Bayesian networks}.
\newblock {\em Journal of Artificial Intelligence Research}, 55:1135--1178, apr
  2016.

\bibitem{Albrecht_stone_2019}
S~V Albrecht and P~Stone.
\newblock {Reasoning about hypothetical agent behaviours and their parameters}.
\newblock In {\em Proceedings of the International Joint Conference on
  Autonomous Agents and Multiagent Systems, AAMAS}, volume~1, pages 547--555.
  International Foundation for Autonomous Agents and Multiagent Systems
  (IFAAMAS), 2017.

\bibitem{ALBRECHT201866}
S~V Albrecht and P~Stone.
\newblock {Autonomous agents modelling other agents: A comprehensive survey and
  open problems}.
\newblock {\em Artificial Intelligence}, 258:66--95, 2018.

\bibitem{Albrecht2019}
Stefano~V Albrecht and Subramanian Ramamoorthy.
\newblock {Comparative Evaluation of Multiagent Learning Algorithms in a
  Diverse Set of Ad Hoc Team Problems}, 2019.

\bibitem{Barrett2015}
S~Barrett and P~Stone.
\newblock {Cooperating with unknown teammates in complex domains: A robot
  soccer case study of ad hoc teamwork}.
\newblock In {\em Proceedings of the National Conference on Artificial
  Intelligence}, volume~3, pages 2010--2016. AI Access Foundation, jun 2015.

\bibitem{Evalulation_of_adhoc_teamwork_Barrett_Stone_Kraus}
S~Barrett, P~Stone, and S~Kraus.
\newblock {Empirical evaluation of ad hoc teamwork in the pursuit domain}.
\newblock In {\em 10th International Conference on Autonomous Agents and
  Multiagent Systems {(AAMAS} 2011), Taipei, Taiwan, May 2-6, 2011, Volume
  1-3}, pages 567--574, 2011.

\bibitem{Barrett2017}
Samuel Barrett, Avi Rosenfeld, Sarit Kraus, and Peter Stone.
\newblock {Making friends on the fly: Cooperating with new teammates}.
\newblock {\em Artificial Intelligence}, 242:132--171, jan 2017.

\bibitem{Brown2020}
Noam Brown, Anton Bakhtin, Adam Lerer, and Qucheng Gong.
\newblock {Combining deep reinforcement learning and search for
  imperfect-information games}.
\newblock In {\em 34th Conference on Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem{Brown2017}
Noam Brown and Tuomas Sandholm.
\newblock {Safe and nested subgame solving for imperfect-information games},
  2017.

\bibitem{he_om_DRL}
Arnaud Doucet and Adam~M Johansen.
\newblock {A Tutorial on Particle Filtering and Smoothing: Fifteen years
  later}.
\newblock Technical report.

\bibitem{Hayashi_et_al2020}
A~Hayashi, D~Ruiken, T~Hasegawa, and C~Goerick.
\newblock {Reasoning about uncertain parameters and agent behaviors through
  encoded experiences and belief planning}.
\newblock {\em Artificial Intelligence}, 280:103228, 2020.

\bibitem{Hernandez-Leal_MAL_Survey}
P~Hernandez-Leal, M~Kaisers, T~Baarslag, and E~de~Cote.
\newblock {A Survey of Learning in Multiagent Environments: Dealing with
  Non-Stationarity}.
\newblock {\em CoRR}, abs/1707.0, 2017.

\bibitem{Katt2017}
Sammie Katt, Frans~A Oliehoek, and Christopher Amato.
\newblock {Learning in POMDPs with monte carlo tree search}.
\newblock In {\em International Conference on Machine Learning}, 2017.

\bibitem{Leibo2017}
Joel~Z Leibo, Vinicius Zambaldi, Marc Lanctot, Janusz Marecki, and Thore
  Graepel.
\newblock {Multi-agent reinforcement learning in sequential social dilemmas}.
\newblock In {\em Proceedings of the International Joint Conference on
  Autonomous Agents and Multiagent Systems, AAMAS}, volume~1, pages 464--473,
  2017.

\bibitem{Lerer2019}
Adam Lerer, Hengyuan Hu, Jakob Foerster, and Noam Brown.
\newblock {Improving policies via search in cooperative partially observable
  games}, 2019.

\bibitem{mealing_shapiro_OM_by_expectation_maximisation}
R~Mealing and J~Shapiro.
\newblock {Opponent Modeling by Expectation-Maximization and Sequence
  Prediction in Simplified Poker}.
\newblock {\em {IEEE} Trans. Comput. Intellig. and {AI} in Games}, 9(1):11--24,
  2017.

\bibitem{InteractivePOMDPs_panella_gmytrasiewicz}
A~Panella and P~Gmytrasiewicz.
\newblock {Interactive POMDPs with finite-state models of other agents}.
\newblock {\em Autonomous Agents and Multi-Agent Systems}, 31(4):861--904,
  2017.

\bibitem{Papoudakis2020}
Georgios Papoudakis, Filippos Christianos, Lukas Sch{\"{a}}fer, and Stefano~V
  Albrecht.
\newblock {Comparative Evaluation of Multi-Agent Deep Reinforcement Learning
  Algorithms}, 2020.

\bibitem{Ross2011}
St{\'{e}}phane Ross, Joelle Pineau, Brahim Chaib-Draa, and Pierre Kreitmann.
\newblock {Bayesian approach for learning and planning in partially observable
  markov decision processes}.
\newblock {\em Journal of Machine Learning Research}, 12:1729--1770, 2011.

\bibitem{AlphaGo}
D~Silver, A~Huang, C~Maddison, A~Guez, L~Sifre, G~van~den Driessche,
  J~Schrittwieser, I~Antonoglou, V~Panneershelvam, M~Lanctot, S~Dieleman,
  D~Grewe, J~Nham, N~Kalchbrenner, I~Sutskever, T~Lillicrap, M~Leach,
  K~Kavukcuoglu, T~Graepel, and D~Hassabis.
\newblock {Mastering the game of Go with deep neural networks and tree search}.
\newblock {\em Nature}, 529(7587):484--489, 2016.

\bibitem{Silver2010}
David Silver and Joel Veness.
\newblock {Monte-Carlo planning in large POMDPs}.
\newblock In {\em Advances in Neural Information Processing Systems 23: 24th
  Annual Conference on Neural Information Processing Systems 2010, NIPS 2010},
  2010.

\end{thebibliography}
